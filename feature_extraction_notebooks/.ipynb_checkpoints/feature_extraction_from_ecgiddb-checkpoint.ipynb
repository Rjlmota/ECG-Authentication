{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from utilities import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alguns parametros especificos para este dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../physiobank_tool/ecgiddb/per_person'\n",
    "number_of_segments = 120\n",
    "low_cut = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo os arquivos que cont√©m o sinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data for the following drivers:\n",
      " ['person1', 'person2', 'person3', 'person4', 'person5', 'person6', 'person7', 'person8', 'person9', 'person10', 'person11', 'person12', 'person13', 'person14', 'person15', 'person16', 'person17', 'person18', 'person19', 'person20', 'person21', 'person22', 'person23', 'person24', 'person25', 'person26', 'person27', 'person28', 'person29', 'person30', 'person31', 'person32', 'person33', 'person34', 'person35', 'person36', 'person37', 'person38', 'person39', 'person40', 'person41', 'person42', 'person43', 'person44', 'person45', 'person46', 'person47', 'person48', 'person49', 'person50', 'person51', 'person52', 'person53', 'person54', 'person55', 'person56', 'person57', 'person58', 'person59', 'person60', 'person61', 'person62', 'person63', 'person64', 'person65', 'person66', 'person67', 'person68', 'person69', 'person70', 'person71', 'person72']\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "with open(path+'/header.txt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        #print(row)\n",
    "        files.append(row[0])\n",
    "print(\"Read data for the following drivers:\\n\", files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os arquivos para um DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    ''' docstring here later '''\n",
    "    cols_of_interest = [0,1,2]\n",
    "    ecg_data = pd.read_csv(f'{path}/{file_name}.csv', usecols=cols_of_interest)\n",
    "    # drop useless header\n",
    "    ecg_data = ecg_data.drop(ecg_data.index[0])\n",
    "    # name columns\n",
    "    ecg_data.columns = ['time', 'ECG', 'ECGF']\n",
    "    # cast some columns to float\n",
    "    ecg_data['time'] = ecg_data['time'].astype(float)\n",
    "    ecg_data['ECG'] = ecg_data['ECG'].astype(float)\n",
    "    \n",
    "    return ecg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(ecg_data, file_name, number_of_segments, low_cut):\n",
    "    \"\"\"adiciona a docstring aqui depois\"\"\"\n",
    "    sample_rate = utilities.detect_sample_rate(ecg_data)\n",
    "    print(sample_rate)\n",
    "    high_cut = sample_rate/3.0\n",
    "    \n",
    "    data_preparation_pipeline = Pipeline([\n",
    "        ('filtering', utilities.Filter(sample_rate, low_cut, high_cut)),\n",
    "        ('feature_detection', utilities.FeatureExtractor(number_of_segments, sample_rate)),\n",
    "        ])\n",
    "\n",
    "    extracted_features_df = data_preparation_pipeline.fit_transform(ecg_data['ECG'])\n",
    "    #print(extracted_features_df)\n",
    "    #extracted_features_df.to_csv(f\"{path}_output/{file_name}.csv\")\n",
    "    extracted_features_df.reset_index(drop=True, inplace=True)\n",
    "    return extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renato/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/renato/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "features_df = pd.DataFrame()\n",
    "for file in files:\n",
    "    ecg_data = read_file(file)\n",
    "    current_df = run(ecg_data, file, number_of_segments, low_cut)\n",
    "    current_df['person'] = file\n",
    "    features_df = pd.concat([current_df, features_df], ignore_index=True)\n",
    "\n",
    "features_df.to_csv(\"../extracted_features_files/ecgiddb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dando uma olhada no signal e a filtragem obtida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data = read_file(files[1])\n",
    "sample_rate = utilities.detect_sample_rate(ecg_data)\n",
    "two_seconds = ecg_data['ECG'][0:sample_rate*2]\n",
    "plt.figure(figsize=(20, 7), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "list_of_filters = [utilities.Filter(sample_rate, x, sample_rate/3.0) for x in np.linspace(0.1, 1, 10)]\n",
    "list_of_filtered_signals = [x.fit_transform(two_seconds) + index for index, x in enumerate(list_of_filters)]\n",
    "\n",
    "for index, signal in enumerate(list_of_filtered_signals):\n",
    "    plt.plot(signal, label=f'filtered_{index}')\n",
    "plt.plot(two_seconds+1.0, label='original')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
